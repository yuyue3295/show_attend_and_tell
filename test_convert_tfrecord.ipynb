{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import logging\n",
    "import sys\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordSequence(object):\n",
    "    def __init__(self,train_captions,max_len):\n",
    "        self.dict = {'<pad>': 0, '<start>': 1, '<end>': 2,'<unknow>':3}\n",
    "        self.corpus = train_captions\n",
    "        self._word_count()\n",
    "        self.max_len =max_len\n",
    "        \n",
    "    def _word_count(self):\n",
    "        word_dict = {}\n",
    "        for word in self.corpus:\n",
    "            if word not in word_dict:\n",
    "                word_dict[word] = 0\n",
    "            word_dict[word] = word_dict[word]+1\n",
    "        print(len(word_dict))\n",
    "        word_dict = {k:v for k,v in word_dict.items() if v>=2}\n",
    "        print(len(word_dict))\n",
    "        vocabulary = sorted(word_dict.items(), key=lambda x:-x[1])\n",
    "        for i in vocabulary:\n",
    "            self.dict[i[0]] = len(self.dict)\n",
    "        self.id2word_dict = {value:key for key,value in self.dict.items()}\n",
    "        \n",
    "        \n",
    "    def word2id(self,word_list):\n",
    "        word_list.append('<end>')\n",
    "        ids = []\n",
    "        for word in word_list:\n",
    "            if word in self.dict:\n",
    "                ids.append(self.dict[word])\n",
    "            else:\n",
    "                ids.append(3)\n",
    "        return ids\n",
    "    \n",
    "    def id2word(self,ids):\n",
    "        words = []\n",
    "        for i in ids:\n",
    "            words.append(self.id2word_dict[i])\n",
    "        print(words)\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_length(string):\n",
    "    length = len(string.split(' '))\n",
    "    return length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image(filename, hps):\n",
    "    image = hps.data_dir+filename\n",
    "    img_buffer = None\n",
    "    with open(image,'rb') as f:\n",
    "        img_buffer = f.read()\n",
    "    return img_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    \"\"\"Wrapper for inserting int64 features into Example proto.\n",
    "    \n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = tf.contrib.training.HParams(\n",
    "        num_shards=20,\n",
    "        num_threads=5,\n",
    "        dataset_name='satellite',\n",
    "        data_dir='data/crop_imgs/',\n",
    "        output_directory='./tfrecords'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_example(filename, image_buffer,caption,caption_len):\n",
    "    \"\"\"Build an Example proto for an example.\n",
    "    Args:\n",
    "      filename: string, path to an image file, e.g., '36979.jpg'\n",
    "      image_buffer: string, JPEG encoding of RGB image\n",
    "      text: string,image captions\n",
    "      height: integer, image height in pixels\n",
    "      width: integer, image width in pixels\n",
    "    Returns:\n",
    "      Example proto\n",
    "    \"\"\"\n",
    "    height=224\n",
    "    width=224\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': _int64_feature(height),\n",
    "        'image/width': _int64_feature(width),\n",
    "        'image/caption': _bytes_feature(caption.encode()),\n",
    "        'image/caption_len':_int64_feature(caption_len),\n",
    "        'image/filename': _bytes_feature(filename.encode()),\n",
    "        'image/img': _bytes_feature(image_buffer)}))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 158915/158915 [00:01<00:00, 142193.10it/s]\n"
     ]
    }
   ],
   "source": [
    "captions = {}\n",
    "with codecs.open ('./data/results_20130124.token','r','utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    bar = tqdm.tqdm(lines)\n",
    "    for line in bar:\n",
    "        line = line.strip()\n",
    "        words = line.split(\"\\t\")\n",
    "        if words[0].split(\"#\")[0] not in captions:\n",
    "            captions[words[0].split(\"#\")[0]]=[]\n",
    "        else:\n",
    "            caption = words[1]\n",
    "            caption = caption.strip().lower()\n",
    "            caption = caption.replace(',', '').replace(\"'\", '').replace('\"', '')\n",
    "            caption = caption.replace('&', 'and').replace('(', '').replace(')', '').split()\n",
    "            caption = [w for w in caption if len(w) > 0]\n",
    "            captions[words[0].split(\"#\")[0]].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_words = []\n",
    "for k,values in captions.items():\n",
    "    for value in values:\n",
    "        captions_words.extend(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1498287"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(captions_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17119\n",
      "10652\n"
     ]
    }
   ],
   "source": [
    "ws = WordSequence(captions_words,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ws.pkl','wb') as f:\n",
    "    pickle.dump(obj=ws,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_ids = {}\n",
    "# ws = None\n",
    "# with open('./ws.pkl','rb') as f:\n",
    "#     ws = pickle.load(f)\n",
    "for key in list(captions.keys()):\n",
    "    ids = []\n",
    "    for integer in ws.word2id(captions[key][1]):\n",
    "        ids.append(str(integer))\n",
    "    ids = ' '.join(ids)\n",
    "    captions_ids[key]=ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(captions_ids.items())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_caption = captions['36979.jpg']\n",
    "print(' '.join(img_caption[1]))\n",
    "img_caption = ' '.join(img_caption[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ids_length(list(captions_ids.items())[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image_files_batch(thread_index,ranges,filenames,num_shards):\n",
    "    \"\"\"Processes and saves list of images as TFRecord in 1 thread.\n",
    "    Args:\n",
    "      coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "      thread_index: integer, unique batch to run index is within [0, len(ranges)).\n",
    "      ranges: list of pairs of integers specifying ranges of each batches to\n",
    "        analyze in parallel.\n",
    "      name: string, unique identifier specifying the data set\n",
    "      filenames: list of strings; each string is a path to an image file\n",
    "      texts: list of strings; each string is human readable, e.g. 'dog'\n",
    "      num_shards: integer number of shards for this data set.\n",
    "    \"\"\"\n",
    "    # Each thread produces N shards where N = int(num_shards / num_threads).\n",
    "    # For instance, if num_shards = 128, and the num_threads = 2, then the first\n",
    "    # thread would produce shards [0, 64).\n",
    "    num_threads = len(ranges) #线程的数目，\n",
    "    assert not num_shards % num_threads #确认，num_shards，也就是想要分片的数目是线程数目的整数倍。\n",
    "    num_shards_per_batch = int(num_shards / num_threads) #num_shards_pre_batch,每个线程需要生成多个shard\n",
    "    shard_ranges = np.linspace(ranges[thread_index][0],\n",
    "                               ranges[thread_index][1],\n",
    "                               num_shards_per_batch + 1).astype(int)#这个线程需要处理的图像索引的范围。\n",
    "    num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0] #这个线程需要处理多少个图像。\n",
    "    counter = 0\n",
    "    \n",
    "    for s in range(num_shards_per_batch):\n",
    "        # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n",
    "        shard = thread_index * num_shards_per_batch + s #可以标识一个shard分片\n",
    "        output_filename = '%s_%.5d-of-%.5d.tfrecord' % ('1', shard, num_shards)\n",
    "        output_file = os.path.join(hps.output_directory, output_filename)\n",
    "        writer = tf.python_io.TFRecordWriter(output_file)\n",
    "        shard_counter = 0\n",
    "        files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n",
    "        for i in files_in_shard:\n",
    "            image_file_name = filenames[i]\n",
    "            image_caption = captions_ids[image_file_name]\n",
    "            caption_len = get_ids_length(image_caption)\n",
    "            image_buffer = _process_image(image_file_name, hps) #读取img的图像、高度和宽度\n",
    "            example = _convert_to_example(image_file_name, image_buffer,image_caption,caption_len)#将想要保存的数据封装成tf.train.Example\n",
    "            writer.write(example.SerializeToString()) # 将Example数据写入到tfrecord 文件中。\n",
    "            shard_counter += 1\n",
    "            counter += 1\n",
    "\n",
    "            if not counter % 1000:\n",
    "                logging.info('%s [thread %d]: Processed %d of %d images in thread batch.' %\n",
    "                             (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        writer.close()\n",
    "        logging.info('%s [thread %d]: Wrote %d images to %s' %\n",
    "                     (datetime.now(), thread_index, shard_counter, output_file))\n",
    "        sys.stdout.flush()\n",
    "        shard_counter = 0\n",
    "    logging.info('%s [thread %d]: Wrote %d images to %d shards.' %\n",
    "                 (datetime.now(), thread_index, counter, num_files_in_thread))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image_files(name, filenames,num_shards,hps):\n",
    "    \"\"\"Process and save list of images as TFRecord of Example protos.\n",
    "    Args:\n",
    "      name: string, unique identifier specifying the data set\n",
    "      filenames: list of strings; each string is a path to an image file\n",
    "      texts: list of strings; each string is human readable, e.g. 'dog'\n",
    "      labels: list of integer; each integer identifies the ground truth\n",
    "      num_shards: integer number of shards for this data set.\n",
    "    \"\"\"\n",
    "    # Break all images into batches with a [ranges[i][0], ranges[i][1]].\n",
    "    '''\n",
    "    spacing 是文件序号的空间，比如文件数目是20，有2个线程来处理这些文件，那么spacing分成3个数，\n",
    "    0,10,20\n",
    "    则两个线程分别需要处理的序号是（0,10），（10,20），\n",
    "    通过np.arrange(0,10)就会生成[0,1,2,...,9]这些序号列表，\n",
    "    通过np.arrange(10,20)就会生成[10,11,12,...,19]这些序号列表。\n",
    "    '''\n",
    "    spacing = np.linspace(0, len(filenames), hps.num_threads + 1).astype(np.int)\n",
    "    ranges = []\n",
    "    for i in range(len(spacing) - 1):\n",
    "        ranges.append([spacing[i], spacing[i + 1]])\n",
    "    # Launch a thread for each batch.\n",
    "    logging.info('Launching %d threads for spacings: %s' % (hps.num_threads, ranges))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Create a mechanism for monitoring when all threads are finished.\n",
    "    coord = tf.train.Coordinator()\n",
    "    # Create a generic TensorFlow-based utility for converting all image codings.\n",
    "    threads = []\n",
    "    for thread_index in range(len(ranges)):\n",
    "        args = (thread_index, ranges,filenames,num_shards)\n",
    "        t = threading.Thread(target=_process_image_files_batch, args=args)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    # Wait for all the threads to terminate.\n",
    "    coord.join(threads)\n",
    "    logging.info('%s: Finished writing all %d images in data set.' %\n",
    "                 (datetime.now(), len(filenames)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = list(captions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "_process_image_files('name', file_names,hps.num_shards,hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(['./tfrecords/1.tfrecord'])#生成一个queue队列\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)#返回文件名和文件\n",
    "features = tf.parse_single_example(serialized_example,\n",
    "                                   features={\n",
    "                                       'image/height':tf.FixedLenFeature([], tf.int64),\n",
    "                                        'image/width':tf.FixedLenFeature([], tf.int64),\n",
    "                                        'image/caption':tf.FixedLenFeature([], tf.string),\n",
    "                                        'image/filename':tf.FixedLenFeature([], tf.string),\n",
    "                                        'image/img':tf.FixedLenFeature([], tf.string)\n",
    "                                   })#将image数据和label取出来\n",
    "\n",
    "img = features['image/img']\n",
    "img = tf.image.decode_jpeg(img)\n",
    "img_caption = features['image/caption']\n",
    "height=tf.cast(features['image/height'],tf.int32)\n",
    "width=tf.cast(features['image/width'],tf.int32)\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "result_height,result_width,result_img,result_img_caption = sess.run([height,width,img,img_caption])\n",
    "plt.imshow(result_img)\n",
    "plt.title(' '.join([str(result_height),str(result_width)]))\n",
    "plt.axis(\"off\")\n",
    "print(result_img_caption.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ws.pkl','rb')\n",
    "ws = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption1 = captions[file_names[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./caption_file/captions.txt','w') as g:\n",
    "    bar = tqdm.tqdm(list(captions.keys()))\n",
    "    for i in bar:\n",
    "        ids = []\n",
    "        for j in ws.word2id(captions[i][1]):\n",
    "            ids.append(str(j))\n",
    "        id_string = ' '.join(ids)\n",
    "        g.write(id_string+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "spacing = np.linspace(0, 101, 20 + 1).astype(np.int)\n",
    "print(spacing)\n",
    "ranges = []\n",
    "for i in range(len(spacing) - 1):\n",
    "    ranges.append([spacing[i], spacing[i + 1]])\n",
    "print(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_dataset(name, hps,filenames,texts):\n",
    "    \"\"\"Process a complete data set and save it as a TFRecord.\n",
    "    Args:\n",
    "      name: string, unique identifier specifying the data set.\n",
    "      num_shards: integer number of shards for this data set.\n",
    "    \"\"\"\n",
    "    _process_image_files(name, filenames, texts,hps.train_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('./data/crop_imgs/3025093.jpg')\n",
    "#     print(type(img))\n",
    "#     print(dir(img))\n",
    "height,width = img.size\n",
    "img_buffer = img.tobytes()\n",
    "_bytes_feature(img_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_process_image('3025093.jpg',hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
